{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Notebook and code created by Bruna Lopes and Bruno Amorim, inspired by alphascs examples.\n",
    "\n",
    "All the source code can be found in (github name).\n",
    "\n",
    "The functions load_data, separate_sleep_stages, find_peaks, display_topomap, display_ffts and display_atoms are all implemented in the repository fo this project. To be able to import them, you can clone our repository."
   ],
   "id": "d3691b36dd4a3e84"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "git clone https://github.com/brunaafl/TS_CSC_MEG\n",
    "\n",
    "cd TS_CSC_MEG/"
   ],
   "id": "dfb4fbe6ec7d54e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Functions",
   "id": "e99301b0e98e3c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "rhythms = {4:'Delta',\n",
    "           8:'Theta',\n",
    "           12:'Alpha-Mu',\n",
    "           30:'Beta',\n",
    "           100: 'Spindle'}\n",
    "\n",
    "\n",
    "def display_atom(model, i_atom, info, sfreq=150):\n",
    "\n",
    "    n_plots = 3\n",
    "    figsize = (n_plots * 5, 5.5)\n",
    "    fig, axes = plt.subplots(1, n_plots, figsize=figsize, squeeze=False)\n",
    "\n",
    "    # Plot the spatial map of the learn atom using mne topomap\n",
    "    ax = axes[0, 0]\n",
    "    u_hat = model.u_hat_[i_atom]\n",
    "    mne.viz.plot_topomap(u_hat, info, axes=ax, show=False)\n",
    "    ax.set(title='Learned spatial pattern')\n",
    "\n",
    "    # Plot the temporal pattern of the learn atom\n",
    "    ax = axes[0, 1]\n",
    "    v_hat = model.v_hat_[i_atom]\n",
    "    t = np.arange(v_hat.size) / sfreq\n",
    "    ax.plot(t, v_hat)\n",
    "    ax.set(xlabel='Time (sec)', title='Learned temporal waveform')\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Plot the psd of the time atom\n",
    "    ax = axes[0, 2]\n",
    "    psd = np.abs(np.fft.rfft(v_hat)) ** 2\n",
    "    frequencies = np.linspace(0, sfreq / 2.0, len(psd))\n",
    "    ax.semilogy(frequencies, psd)\n",
    "    ax.set(xlabel='Frequencies (Hz)', title='Power Spectral Density')\n",
    "    ax.grid(True)\n",
    "    ax.set_xlim(0, 30)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def display_atoms(model, n_atoms, rows, columns, sfreq, savefig=\"atoms_somato\"):\n",
    "    if rows * columns < n_atoms:\n",
    "        raise ValueError(\"The grid size (rows x columns) must be at least equal to n_atoms\")\n",
    "\n",
    "    figsize = (columns * 5, rows * 5.5)\n",
    "    fig, axes = plt.subplots(rows, columns, figsize=figsize, squeeze=False)\n",
    "\n",
    "    for i_atom in range(n_atoms):\n",
    "        row = i_atom // columns\n",
    "        col = i_atom % columns\n",
    "        ax = axes[row, col]\n",
    "\n",
    "        v_hat = model.v_hat_[i_atom]\n",
    "        t = np.arange(v_hat.size) / sfreq\n",
    "\n",
    "        ax.plot(t, v_hat)\n",
    "        ax.set(xlabel='Time (sec)', title=f'Atom {i_atom + 1}')\n",
    "        ax.grid(True)\n",
    "\n",
    "    for i in range(n_atoms, rows * columns):\n",
    "        row = i // columns\n",
    "        col = i % columns\n",
    "        axes[row, col].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"../figures/{savefig}.pdf\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def display_ffts(model, n_atoms, rows, columns, sfreq, savefig=\"topomap_ffts\"):\n",
    "    if rows * columns < n_atoms:\n",
    "        raise ValueError(\"The grid size (rows x columns) must be at least equal to n_atoms\")\n",
    "\n",
    "    figsize = (columns * 5, rows * 5.5)\n",
    "    fig, axes = plt.subplots(rows, columns, figsize=figsize, squeeze=False)\n",
    "\n",
    "    for i_atom in range(n_atoms):\n",
    "        row = i_atom // columns\n",
    "        col = i_atom % columns\n",
    "        ax = axes[row, col]\n",
    "\n",
    "        v_hat = model.v_hat_[i_atom]\n",
    "        psd = np.abs(np.fft.rfft(v_hat)) ** 2\n",
    "        frequencies = np.linspace(0, sfreq / 2.0, len(psd))\n",
    "        ax.semilogy(frequencies, psd)\n",
    "        ax.set(xlabel='Frequencies (Hz)', title=f'Atom {i_atom + 1}')\n",
    "        ax.grid(True)\n",
    "        ax.set_xlim(0, 30)\n",
    "\n",
    "    for i in range(n_atoms, rows * columns):\n",
    "        row = i // columns\n",
    "        col = i % columns\n",
    "        axes[row, col].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"../figures/{savefig}.pdf\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def display_topomap(model, n_atoms, rows, columns, info, savefig=\"topomap_somato\"):\n",
    "    if rows * columns < n_atoms:\n",
    "        raise ValueError(\"The grid size (rows x columns) must be at least equal to n_atoms\")\n",
    "\n",
    "    figsize = (columns * 5, rows * 5.5)\n",
    "    fig, axes = plt.subplots(rows, columns, figsize=figsize, squeeze=False)\n",
    "\n",
    "    for i_atom in range(n_atoms):\n",
    "        row = i_atom // columns\n",
    "        col = i_atom % columns\n",
    "        ax = axes[row, col]\n",
    "\n",
    "        u_hat = model.u_hat_[i_atom]\n",
    "        mne.viz.plot_topomap(u_hat, info, axes=ax, show=False)\n",
    "        ax.set(title=f'Atom {i_atom + 1}')\n",
    "\n",
    "    for i in range(n_atoms, rows * columns):\n",
    "        row = i // columns\n",
    "        col = i % columns\n",
    "        axes[row, col].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"../figures/{savefig}.pdf\", dpi=300)\n",
    "    plt.show()\n",
    "\n"
   ],
   "id": "6457dbaa387a90b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from os.path import join\n",
    "from copy import deepcopy\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "from joblib import Memory\n",
    "from scipy.signal.windows import tukey\n",
    "\n",
    "from alphacsc.utils.config import ALPHACSC_CACHE_DIR\n",
    "\n",
    "mem = Memory(location=ALPHACSC_CACHE_DIR, verbose=0)\n",
    "\n",
    "## Adaptation of the code at alphacsc\n",
    "@mem.cache(ignore=['n_jobs'])\n",
    "def load_data(dataset=\"somato\", n_splits=10, sfreq=None, epoch=None, channels= None,\n",
    "              filter_params=[2., None], return_array=True, n_jobs=1):\n",
    "    \"\"\"Load and prepare the somato dataset for multiCSC\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : str in {'somato', 'sample'}\n",
    "        Dataset to load.\n",
    "    n_splits : int\n",
    "        Split the signal in n_split signals of same length before returning it.\n",
    "        If epoch is provided, the signal is instead splitted according to the\n",
    "        epochs and this option is not followed.\n",
    "    sfreq : float\n",
    "        Sampling frequency of the signal. The data are resampled to match it.\n",
    "    epoch : tuple or None\n",
    "        If set to a tuple, extract epochs from the raw data, using\n",
    "        t_min=epoch[0] and t_max=epoch[1]. Else, use the raw signal, divided\n",
    "        in n_splits chunks.\n",
    "    filter_params : tuple of length 2\n",
    "        Boundaries of filtering, e.g. (2, None), (30, 40), (None, 40).\n",
    "    return_array : boolean\n",
    "        If True, return an NumPy array, instead of mne objects.\n",
    "    n_jobs : int\n",
    "        Number of jobs that can be used for preparing (filtering) the data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : array, shape (n_splits, n_channels, n_times)\n",
    "        The loaded dataset.\n",
    "    info : dict\n",
    "        MNE dictionary of information about recording settings.\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset == 'somato':\n",
    "        pick_types_epoch = dict(meg='grad', eeg=False, eog=True, stim=False)\n",
    "        pick_types_final = dict(meg='grad', eeg=False, eog=False, stim=False)\n",
    "\n",
    "        data_path = mne.datasets.somato.data_path()\n",
    "        subjects_dir = None\n",
    "        file_name = join(data_path, 'sub-01', 'meg',\n",
    "                         'sub-01_task-somato_meg.fif')\n",
    "        raw = mne.io.read_raw_fif(file_name, preload=True)\n",
    "\n",
    "        raw_copy = raw.copy()\n",
    "\n",
    "        # Keep a copy for event extraction\n",
    "        raw_stim = raw.copy()\n",
    "        raw_stim.pick_types(meg=False, stim=True)  # Only keep stim channels for event detection\n",
    "\n",
    "        # Extract events from stim channels\n",
    "        event_id = {'somato': 1}\n",
    "        events = mne.find_events(raw_stim, stim_channel='STI 014')\n",
    "        events = mne.pick_events(events, include=list(event_id.values()))\n",
    "\n",
    "        raw_copy.notch_filter(np.arange(50, 101, 50), n_jobs=n_jobs)\n",
    "\n",
    "        baseline = (None, 0)\n",
    "\n",
    "    elif dataset == 'sleep':\n",
    "        pick_types_epoch = dict(meg=False, eeg=True, eog=True, stim=False)\n",
    "        pick_types_final = dict(meg=False, eeg=True, eog=False, stim=False)\n",
    "\n",
    "        # Load the sleep PhysioNet dataset\n",
    "        subject = 1\n",
    "        subjects_dir = None\n",
    "        [data_fetch] = mne.datasets.sleep_physionet.age.fetch_data(subjects=[subject], recording=[1])\n",
    "\n",
    "        raw = mne.io.read_raw_edf(data_fetch[0],stim_channel=\"Event marker\",infer_types=True,preload=True,)\n",
    "\n",
    "        annot_train = mne.read_annotations(data_fetch[1])\n",
    "        print(annot_train)\n",
    "        raw.set_annotations(annot_train, emit_warning=False)\n",
    "\n",
    "        raw_copy = raw.copy()\n",
    "\n",
    "        # remove 6 and 7 labels\n",
    "\n",
    "        annotation_event_id = {\n",
    "            \"Sleep stage W\": 1,\n",
    "            \"Sleep stage 1\": 2,\n",
    "            \"Sleep stage 2\": 3,\n",
    "            \"Sleep stage 3\": 4,\n",
    "            \"Sleep stage 4\": 4,\n",
    "            \"Sleep stage R\": 5,\n",
    "        }\n",
    "\n",
    "        # Set reference for EEG channels\n",
    "        annot_train.crop(annot_train[1][\"onset\"] - 30 * 60, annot_train[-2][\"onset\"] + 30 * 60)\n",
    "        raw_copy.set_annotations(annot_train, emit_warning=False)\n",
    "\n",
    "        # Extract events based on annotations\n",
    "        events, _ = mne.events_from_annotations(raw_copy, event_id=annotation_event_id, chunk_duration=30.0)\n",
    "\n",
    "        # create a new event_id that unifies stages 3 and 4\n",
    "        event_id = {\n",
    "            \"Sleep stage W\": 1,\n",
    "            \"Sleep stage 1\": 2,\n",
    "            \"Sleep stage 2\": 3,\n",
    "            \"Sleep stage 3/4\": 4,\n",
    "            \"Sleep stage R\": 5,\n",
    "        }\n",
    "\n",
    "        baseline = None\n",
    "\n",
    "    else:\n",
    "        ValueError(\"Dataset must be somato or auditory\")\n",
    "\n",
    "    if channels is not None:\n",
    "        raw_copy = raw_copy.pick_channels(channels, ordered=True)\n",
    "\n",
    "    # Dipole fit information\n",
    "    cov = None  # see below\n",
    "    file_trans = None\n",
    "    file_bem = None\n",
    "\n",
    "    raw_copy.filter(*filter_params, n_jobs=n_jobs)\n",
    "\n",
    "    # Now pick final channel types for the main raw object\n",
    "    raw_copy.pick_types(**pick_types_final)\n",
    "\n",
    "    if dataset == 'somato':\n",
    "        # compute the covariance matrix for somato\n",
    "        picks_cov = mne.pick_types(raw_copy.info, **pick_types_epoch)\n",
    "        epochs_cov = mne.Epochs(raw_copy, events, event_id, tmin=-4, tmax=0,\n",
    "                                picks=picks_cov, baseline=baseline,\n",
    "                                reject=dict(grad=4000e-13),\n",
    "                                preload=True)\n",
    "        epochs_cov.pick_types(**pick_types_final)\n",
    "        cov = mne.compute_covariance(epochs_cov)\n",
    "\n",
    "    if epoch:\n",
    "        t_min, t_max = epoch\n",
    "        print(events)\n",
    "        picks = mne.pick_types(raw_copy.info, **pick_types_epoch)\n",
    "        epochs = mne.Epochs(raw_copy, events, event_id, t_min, t_max, picks=picks,\n",
    "                            baseline=baseline,preload=True)\n",
    "        epochs.pick_types(**pick_types_final)\n",
    "        info = epochs.info\n",
    "\n",
    "        print(epochs)\n",
    "        if sfreq is not None:\n",
    "            epochs = epochs.resample(sfreq, npad='auto', n_jobs=n_jobs)\n",
    "\n",
    "        if return_array:\n",
    "            X = epochs.get_data()\n",
    "\n",
    "    else:\n",
    "        events[:, 0] -= raw_copy.first_samp\n",
    "        if channels is not None:\n",
    "            raw_copy = raw_copy.pick_channels(channels, ordered=True)\n",
    "        raw_copy.pick_types(**pick_types_final)\n",
    "        info = raw_copy.info\n",
    "\n",
    "        if sfreq is not None:\n",
    "            raw_copy, events = raw_copy.resample(sfreq, events=events, npad='auto',\n",
    "                                       n_jobs=n_jobs)\n",
    "\n",
    "        if return_array:\n",
    "            X = raw_copy.get_data()\n",
    "            n_channels, n_times = X.shape\n",
    "            n_times = n_times // n_splits\n",
    "            X = X[:, :n_splits * n_times]\n",
    "            X = X.reshape(n_channels, n_splits, n_times).swapaxes(0, 1)\n",
    "\n",
    "    # Deep copy before modifying info to avoid issues when saving EvokedArray\n",
    "    info = deepcopy(info)\n",
    "    event_info = dict(event_id=event_id,\n",
    "                      events=events,\n",
    "                      subject=dataset,\n",
    "                      subjects_dir=subjects_dir,\n",
    "                      cov=cov,\n",
    "                      file_bem=file_bem,\n",
    "                      file_trans=file_trans)\n",
    "\n",
    "    info['temp'] = event_info\n",
    "\n",
    "    if return_array:\n",
    "        n_splits, n_channels, n_times = X.shape\n",
    "        X *= tukey(n_times, alpha=0.1)[None, None, :]\n",
    "        X /= np.std(X)\n",
    "        return X, info\n",
    "    elif epoch:\n",
    "        return epoch, info\n",
    "    else:\n",
    "        return raw_copy, info\n",
    "\n",
    "\n",
    "def separate_sleep_stages(X, info):\n",
    "\n",
    "    event_id = info['temp']['event_id']  # Mapping of sleep stages\n",
    "    events = info['temp']['events']  # Event data\n",
    "\n",
    "    data_by_stage = {stage: [] for stage in event_id.keys()}\n",
    "\n",
    "    # Sampling frequency (sfreq) is required to slice the data\n",
    "    sfreq = info['sfreq']  # Replace with the correct sampling frequency of your data\n",
    "\n",
    "    # Iterate over events to separate data\n",
    "    j=0\n",
    "    for _, _, stage_id in events:\n",
    "        # Find corresponding stage name\n",
    "        stage_name = next((name for name, sid in event_id.items() if sid == stage_id), None)\n",
    "        if stage_name is None:\n",
    "            continue  # Skip if the event ID does not match any stage\n",
    "        # Store data from each stage in the dict\n",
    "        data_by_stage[stage_name].append(X[j,:,:])\n",
    "        j += 1\n",
    "\n",
    "    X_stage = {}\n",
    "    for stage in data_by_stage.keys():\n",
    "        value = data_by_stage[stage]\n",
    "        if len(value)>0:\n",
    "            concat_values = np.concatenate(value, axis=0)\n",
    "            X_stage[stage] = concat_values[:,None,:]\n",
    "\n",
    "    return X_stage"
   ],
   "id": "be57c8c7ab8959f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Detect neural rhythms",
   "id": "36ee5404d59cd8c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The pattern of our brain waves can change drastically depending on our mental state or task that is being executed. One example of that is during sleep phases, were our brain enters in different rhythmic patterns, related to its level of activity, depending on the sleep stage. These different patterns present distinct frequencies and, therefore, can be distingushed by spectral analysis, such as by looking at their periodogram or spectrogram and detecting the frequencies with the most power.\n",
    "\n",
    "However, this approach fails to identify between Mu and Alpha waves, since their peak frequency lies on the same band, between 8 and 12 Hz. Howerver, they represent very distinct mental states.\n",
    "\n",
    "*Alpha waves* are generated on the thalamus and on the occipital lobe, and are in general found in different sleep stages, as well as might having some relationship with visual memory and perception of mistakes.\n",
    "\n",
    "*Mu waves* are encountered on motor cortex regions and generated by pyramidal neurons. During the performing and perception of motor actions, the decrease or suppression of mu waves can be detected, what is called desynchronization."
   ],
   "id": "6a2f0f7b4eced001"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Let us first define the parameters of our model.\n",
    "\n",
    "sfreq = 150.\n",
    "\n",
    "# Define the shape of the dictionary\n",
    "n_atoms = 25\n",
    "n_times_atom = int(round(sfreq * 1.0))  # 1000. ms\n"
   ],
   "id": "a254546fbcddc93a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Next, we define the parameters for multivariate CSC\n",
    "\n",
    "from alphacsc import BatchCDL\n",
    "cdl = BatchCDL(\n",
    "    # Shape of the dictionary\n",
    "    n_atoms=n_atoms,\n",
    "    n_times_atom=n_times_atom,\n",
    "    # Request a rank1 dictionary with unit norm temporal and spatial maps\n",
    "    rank1=True, uv_constraint='separate',\n",
    "    # Initialize the dictionary with random chunk from the data\n",
    "    D_init='chunk',\n",
    "    # rescale the regularization parameter to be 20% of lambda_max\n",
    "    lmbd_max=\"scaled\", reg=.2,\n",
    "    # Number of iteration for the alternate minimization and cvg threshold\n",
    "    n_iter=100, eps=1e-4,\n",
    "    # solver for the z-step\n",
    "    solver_z=\"lgcd\", solver_z_kwargs={'tol': 1e-2, 'max_iter': 1000},\n",
    "    # solver for the d-step\n",
    "    solver_d='alternate_adaptive', solver_d_kwargs={'max_iter': 300},\n",
    "    # Technical parameters\n",
    "    verbose=1, random_state=0, n_jobs=6)\n",
    "\n"
   ],
   "id": "fc4ff20a43822bef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Loading the somatossesorial dataset\n",
    "\n",
    "t_lim = (-2, 4)\n",
    "X, info = load_data(dataset='somato', epoch=t_lim, sfreq=sfreq)\n"
   ],
   "id": "87a25ea9320570be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Fit the model and learn rank1 atoms\n",
    "cdl.fit(X)\n"
   ],
   "id": "139547bb859437a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "rhythms = {4:'Delta',\n",
    "           8:'Theta',\n",
    "           12:'Alpha-Mu',\n",
    "           30:'Beta'}\n",
    "\n",
    "def find_peaks(model, n_atoms, n=5, figure=False, rows=1, columns=1):\n",
    "\n",
    "    if figure:\n",
    "        figsize = (columns * 5, rows * 5.5)\n",
    "        fig, axes = plt.subplots(rows, columns, figsize=figsize, squeeze=False)\n",
    "\n",
    "    main_rhythm = {}\n",
    "\n",
    "    for i_atom in range(n_atoms):\n",
    "\n",
    "        print(f\"Atom {i_atom+1}\")\n",
    "\n",
    "        v_hat = model.v_hat_[i_atom]\n",
    "        u_hat = model.u_hat_[i_atom]\n",
    "        psd = np.abs(np.fft.rfft(v_hat)) ** 2\n",
    "        frequencies = np.linspace(0, sfreq / 2.0, len(psd))\n",
    "\n",
    "        mask = frequencies<=30\n",
    "        frequencies = frequencies[mask]\n",
    "        psd = psd[mask]\n",
    "        print(frequencies)\n",
    "\n",
    "        peaks_idx = np.argsort(psd)[-n:][::-1]\n",
    "        peaks_freq = frequencies[peaks_idx]\n",
    "\n",
    "        print(peaks_freq)\n",
    "\n",
    "        for v in rhythms.keys():\n",
    "            if peaks_freq[0]<v:\n",
    "\n",
    "                print(f\"    {rhythms[v]} wave\")\n",
    "\n",
    "                # n most relevant channels\n",
    "                idx_sorted = np.argpartition(u_hat, -n)[-n:]\n",
    "                #idx_sorted = idx_sorted[np.argsort(u_hat[idx_sorted])[::-1]]\n",
    "\n",
    "                # most relevant channels\n",
    "                channels = np.array(info.ch_names)[idx_sorted]\n",
    "\n",
    "                print(f\"    {n} most relevant channels:\")\n",
    "                print(f'    {channels}')\n",
    "\n",
    "                main_rhythm[i_atom] = {\"rhythm\": rhythms[v],\n",
    "                                       \"channels\": channels}\n",
    "\n",
    "                if figure:\n",
    "                    row = i_atom // columns\n",
    "                    col = i_atom % columns\n",
    "                    ax = axes[row, col]\n",
    "\n",
    "                    u_hat = model.u_hat_[i_atom]\n",
    "                    mne.viz.plot_topomap(u_hat, info, axes=ax, show=False)\n",
    "                    ax.set(title=f'Atom {i_atom + 1} - Rhythm {rhythms[v]}',)\n",
    "\n",
    "                break\n",
    "\n",
    "    if figure:\n",
    "        for i in range(n_atoms, rows * columns):\n",
    "            row = i // columns\n",
    "            col = i % columns\n",
    "            axes[row, col].axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"../figures/waves_per_region.pdf\", dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "    return main_rhythm\n",
    "\n",
    "main_rhythm = find_peaks(cdl,n_atoms, figure=True, rows=5, columns=5)\n"
   ],
   "id": "71d159f58d0e0cfa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Testing rank-1 hypothesis - Comparing regions",
   "id": "fa21610c61709a24"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The paper imposes a rank-1 constraint over the dictionary of patterns $D$. This constraint facilitates the optimization of the problem transforming it from multivariate to a two-step univariate by changing the computation of the gradient over a $C \\times P$ matrix to over two univariate arrays $u_k \\in \\mathbb{R}^C$ and $v_k \\in \\mathbb{R}^P$. With this constraint, the problem turns into marginally convex on each variable $v_k$ and $u_k$, and can be solved by a normal projected gradient descent.\n",
    "\n",
    "This constraint, however, imposes an implicit hypothesis that, at each time, you can consider that there is a single source region on the brain which generates the signal, that is then reproduced in all other locations of the brain with different intensities.\n"
   ],
   "id": "abc17a14a37f557a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import mne\n",
    "import copy\n",
    "\n",
    "from dtw import dtw\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Let us first define the parameters of our model.\n",
    "\n",
    "sfreq = 150.\n",
    "\n",
    "# Define the shape of the dictionary\n",
    "n_atoms = 25\n",
    "n_times_atom = int(round(sfreq * 1.0))  # 1000. ms\n"
   ],
   "id": "83525b2774d86cc2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Next, we define the parameters for multivariate CSC\n",
    "\n",
    "# Monkey-patch scipy.signal.tukey to point to the correct function\n",
    "scipy.signal.tukey = scipy.signal.windows.tukey\n",
    "\n",
    "cdl = BatchCDL(\n",
    "    # Shape of the dictionary\n",
    "    n_atoms=n_atoms,\n",
    "    n_times_atom=n_times_atom,\n",
    "    # Request a rank1 dictionary with unit norm temporal and spatial maps\n",
    "    rank1=True, uv_constraint='separate',\n",
    "    # Initialize the dictionary with random chunk from the data\n",
    "    D_init='chunk',\n",
    "    # rescale the regularization parameter to be 20% of lambda_max\n",
    "    lmbd_max=\"scaled\", reg=.2,\n",
    "    # Number of iteration for the alternate minimization and cvg threshold\n",
    "    n_iter=100, eps=1e-4,\n",
    "    # solver for the z-step\n",
    "    solver_z=\"lgcd\", solver_z_kwargs={'tol': 1e-2, 'max_iter': 1000},\n",
    "    # solver for the d-step\n",
    "    solver_d='alternate_adaptive', solver_d_kwargs={'max_iter': 300},\n",
    "    # Technical parameters\n",
    "    verbose=1, random_state=0, n_jobs=6)\n",
    "\n"
   ],
   "id": "190b248d1470a25f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, he can chose two regions of the brain that are the most uncorrelated. We can do that by computing the correlation matrix between two regions and separating channels based on the regions of bigger correlation.",
   "id": "306ef65e0592d8db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Here, we load the data from the somato-sensory dataset and preprocess them\n",
    "# in epochs. The epochs are selected around the stim, starting 2 seconds\n",
    "# before and finishing 4 seconds after.\n",
    "\n",
    "t_lim = (-2, 4)\n",
    "\n",
    "X, info= load_data(dataset='somato', epoch=t_lim, sfreq=sfreq)\n",
    "\n",
    "# Separate the channels that are more correlated on two groups\n",
    "n_split = 110\n",
    "n_channels = len(info['ch_names'])\n",
    "\n",
    "all_channels = info['ch_names']\n",
    "channels_1 = all_channels[:n_split] + ['STI 014']\n",
    "channels_2 = all_channels[n_split:] + ['STI 014']\n",
    "\n",
    "X1, info1= load_data(dataset='somato', epoch=t_lim, sfreq=sfreq,channels=channels_1)\n",
    "X2, info2= load_data(dataset='somato', epoch=t_lim, sfreq=sfreq,channels=channels_2)\n"
   ],
   "id": "82d2a399d87303c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First, let's see the atoms found when all data is used for solving the optimization problem",
   "id": "303767a1c6a7bd46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Learn rank-1 atoms\n",
    "cdl_all = copy.deepcopy(cdl)\n",
    "cdl_all.fit(X)"
   ],
   "id": "4c4a150c1e1f66b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# display all\n",
    "display_atoms(cdl_all, n_atoms, 5, 5, sfreq)\n",
    "display_ffts(cdl_all, n_atoms, 5, 5, sfreq)\n",
    "display_topomap(cdl_all, n_atoms, 5, 5, info)"
   ],
   "id": "2172bb96a5511038"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, let's separate into regions",
   "id": "b6c16b091f93268b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define the shape of the dictionary\n",
    "n_atoms = 10\n",
    "n_times_atom = int(round(sfreq * 1.0))  # 1000. ms\n",
    "\n",
    "cdl = BatchCDL(\n",
    "    # Shape of the dictionary\n",
    "    n_atoms=n_atoms,\n",
    "    n_times_atom=n_times_atom,\n",
    "    # Request a rank1 dictionary with unit norm temporal and spatial maps\n",
    "    rank1=True, uv_constraint='separate',\n",
    "    # Initialize the dictionary with random chunk from the data\n",
    "    D_init='chunk',\n",
    "    # rescale the regularization parameter to be 20% of lambda_max\n",
    "    lmbd_max=\"scaled\", reg=.2,\n",
    "    # Number of iteration for the alternate minimization and cvg threshold\n",
    "    n_iter=100, eps=1e-4,\n",
    "    # solver for the z-step\n",
    "    solver_z=\"lgcd\", solver_z_kwargs={'tol': 1e-2, 'max_iter': 1000},\n",
    "    # solver for the d-step\n",
    "    solver_d='alternate_adaptive', solver_d_kwargs={'max_iter': 300},\n",
    "    # Technical parameters\n",
    "    verbose=1, random_state=0, n_jobs=6)\n",
    "\n"
   ],
   "id": "2c45ace4e5ad673d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Learn rank-1 atoms for each separate part of the brain\n",
    "\n",
    "# Separate the problem into 2 different\n",
    "cdl_1 = copy.deepcopy(cdl)\n",
    "cdl_2 = copy.deepcopy(cdl)\n",
    "\n",
    "cdl_1.fit(X1)\n",
    "cdl_2.fit(X2)\n"
   ],
   "id": "1c7008220f0f8e6e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can see that, even in two different regions, there are few region-specific patterns, and most o the atoms found on each of the regions can be related to each other and to the atoms found when using all regions of the brain to train the CSC model.",
   "id": "149d7257f91be0e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Display the 4-th atom, which displays a :math:`\\mu`-waveform in its temporal\n",
    "# pattern.\n",
    "\n",
    "display_atoms(cdl_1, n_atoms, 2, 5, sfreq, savefig=\"atoms_somato_1\")\n",
    "display_ffts(cdl_1, n_atoms, 2, 5, sfreq, savefig = \"topomap_ffts_1\")\n",
    "display_topomap(cdl_1, n_atoms, 2, 5, info1, savefig = \"topomap_somato_1\")\n",
    "\n",
    "display_atoms(cdl_2, n_atoms, 2, 5, sfreq, savefig=\"atoms_somato_2\")\n",
    "display_ffts(cdl_2, n_atoms, 2, 5, sfreq, savefig = \"topomap_ffts_2\")\n",
    "display_topomap(cdl_2, n_atoms, 2, 5, info2, savefig = \"topomap_somato_2\")\n"
   ],
   "id": "6c9fc284d0fec70c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def distance(v_hat_1, v_hat_2, n1, n2):\n",
    "    table=np.zeros(shape=(n1, n2))\n",
    "\n",
    "    for i in range(n_atoms):\n",
    "        align_row = []\n",
    "        for j in range(i,n_atoms):\n",
    "\n",
    "            alignment = dtw(v_hat_1[i], v_hat_2[j],keep_internals=True)\n",
    "            align_row.append(alignment)\n",
    "            table[i,j]=alignment.distance\n",
    "            table[j,i]=alignment.distance\n",
    "    return table"
   ],
   "id": "6ccee714f97f084b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compare the atoms found in the two regions\n",
    "\n",
    "# Compute the dtw distance between atoms found on each region\n",
    "v_hat_1 = cdl_1.v_hat_\n",
    "v_hat_2 = cdl_2.v_hat_\n",
    "\n",
    "table = distance(v_hat_1, v_hat_2, n_atoms, n_atoms)\n",
    "\n",
    "columns = [f\"Atom {i}\" for i in range(1,1+n_atoms)]\n",
    "\n",
    "min_index = np.argmin(table)\n",
    "row, col = np.unravel_index(min_index, table.shape)\n",
    "\n",
    "# Plot the most similar atoms\n",
    "min_distance = table[row,col]\n",
    "atom_row = v_hat_1[row]\n",
    "atom_col = v_hat_2[col]\n",
    "\n",
    "figsize = (11,5)\n",
    "fig, axes = plt.subplots(1, 2, figsize=figsize, squeeze=False)\n",
    "\n",
    "t = np.arange(atom_row.size)/sfreq\n",
    "\n",
    "ax1 = axes[0,0]\n",
    "ax1.plot(t, atom_row)\n",
    "ax1.set(xlabel='Time (sec)', title=f'Atom {row + 1}')\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2 = axes[0,1]\n",
    "ax2.plot(t, atom_col)\n",
    "ax2.set(xlabel='Time (sec)', title=f'Atom {col + 1}')\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/most_similar_atoms.pdf\", dpi=300)\n",
    "plt.show()\n",
    "\n"
   ],
   "id": "46e17af1d86ff6e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot the distance between atoms\n",
    "\n",
    "table_df = pd.DataFrame(table, columns=columns)\n",
    "table_df.index = columns\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(table_df, annot=True, cmap=\"YlGnBu\", linewidths=0.5, ax=ax)\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig(\"../figures/distance_atoms.pdf\", dpi=300)\n",
    "# Show the plot\n",
    "plt.show()\n"
   ],
   "id": "6ce59859816f57b5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Sleep dataset",
   "id": "5a1708c1938584aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "It is important to test the robustness of the model by seeing it work on a different dataset. We chose a sleep dataset since each raw trial can be segmented in epochs corresponding to a specific sleep stage.\n",
    "\n",
    "In this sense, given that each sleep stage generates a specific behaviour in the brain, they are in general associated with different bands. In general, a wave from a stage-1 state is characterized by relatively low-frequencies (alpha, ranging from 8-12Hz, and theta, from 4-7 Hz), while a deeper sleep, on stages 2 and 3, have mostly even lower frequencies on the delta band (0.5-4 Hz). During REM sleep, however, waves present patterns similar to the ones observed in wakefulness.\n",
    "\n",
    "It could be interesting to try to find the most relevant patterns and peak frequencies from each sleep stage by using the CSC approach developed by the paper."
   ],
   "id": "c05fd88e5bcf1027"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Here, we load the data from a sleep stage dataset from one single subject.\n",
    "# We separate the resultant epochs into their stage so we can analyse if there is\n",
    "# some pattern that the CSC model can recognize to distinguish between stages.\n",
    "\n",
    "sfreq = 100\n",
    "\n",
    "t_lim = (0, 30 - 1/sfreq)\n",
    "X, info = load_data(dataset='sleep', epoch=t_lim, sfreq=sfreq)\n",
    "\n",
    "X_stages = separate_sleep_stages(X, info)\n",
    "\n",
    "stages = ['Sleep stage W','Sleep stage 1','Sleep stage 2','Sleep stage 3/4','Sleep stage R']\n"
   ],
   "id": "62880d242837c4af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Next, we define the parameters for multivariate CSC\n",
    "\n",
    "# First, for solving the optimization problem using data from all stages\n",
    "from alphacsc import BatchCDL\n",
    "\n",
    "# Define the shape of the dictionary\n",
    "n_atoms = 10\n",
    "n_times_atom = int(round(sfreq * 1.0))  # 1000. ms\n",
    "\n",
    "cdl = BatchCDL(\n",
    "    # Shape of the dictionary\n",
    "    n_atoms=n_atoms,\n",
    "    n_times_atom=n_times_atom,\n",
    "    # Request a rank1 dictionary with unit norm temporal and spatial maps\n",
    "    rank1=True, uv_constraint='separate',\n",
    "    # Initialize the dictionary with random chunk from the data\n",
    "    D_init='chunk',\n",
    "    # rescale the regularization parameter to be 20% of lambda_max\n",
    "    lmbd_max=\"scaled\", reg=.2,\n",
    "    # Number of iteration for the alternate minimization and cvg threshold\n",
    "    n_iter=100, eps=1e-4,\n",
    "    # solver for the z-step\n",
    "    solver_z=\"lgcd\", solver_z_kwargs={'tol': 1e-2, 'max_iter': 1000},\n",
    "    # solver for the d-step\n",
    "    solver_d='alternate_adaptive', solver_d_kwargs={'max_iter': 300},\n",
    "    # Technical parameters\n",
    "    verbose=1, random_state=0, n_jobs=6)\n",
    "\n",
    "# Here, we define for each of the stages individually, so we search for less atoms\n",
    "n_atoms_stage = 4\n",
    "n_times_atom = int(round(sfreq * 1.0))  # 1000. ms\n",
    "\n",
    "cdl_stage = BatchCDL(\n",
    "    # Shape of the dictionary\n",
    "    n_atoms=n_atoms_stage,\n",
    "    n_times_atom=n_times_atom,\n",
    "    # Request a rank1 dictionary with unit norm temporal and spatial maps\n",
    "    rank1=True, uv_constraint='separate',\n",
    "    # Initialize the dictionary with random chunk from the data\n",
    "    D_init='chunk',\n",
    "    # rescale the regularization parameter to be 20% of lambda_max\n",
    "    lmbd_max=\"scaled\", reg=.2,\n",
    "    # Number of iteration for the alternate minimization and cvg threshold\n",
    "    n_iter=100, eps=1e-4,\n",
    "    # solver for the z-step\n",
    "    solver_z=\"lgcd\", solver_z_kwargs={'tol': 1e-2, 'max_iter': 1000},\n",
    "    # solver for the d-step\n",
    "    solver_d='alternate_adaptive', solver_d_kwargs={'max_iter': 300},\n",
    "    # Technical parameters\n",
    "    verbose=1, random_state=0, n_jobs=6)\n"
   ],
   "id": "afb5114ca14ebd23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Fit the model and learn rank1 atoms for all\n",
    "cdl.fit(X)\n",
    "\n",
    "###############################################################################\n",
    "# display all\n",
    "display_atoms(cdl, n_atoms, 2, 5, sfreq)\n",
    "display_ffts(cdl, n_atoms, 2, 5, sfreq)\n",
    "#display_topomap(cdl, n_atoms, 5, 5, info)\n"
   ],
   "id": "a13efdd54a176c2c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Now, we can see the patterns found for each different sleep stage\n",
    "\n",
    "rhythms = {4:'Delta',\n",
    "           8:'Theta',\n",
    "           12:'Alpha-Mu',\n",
    "           30:'Beta'}\n",
    "\n",
    "for i, stage in enumerate(stages):\n",
    "\n",
    "    X_stage = X_stages[stage]\n",
    "\n",
    "    cdl_stage_ = copy.deepcopy(cdl_stage)\n",
    "    cdl_stage_.fit(X_stage)\n",
    "\n",
    "    # display found atoms\n",
    "    display_atoms(cdl_stage_, n_atoms_stage, 1, 4, sfreq)\n",
    "    display_ffts(cdl_stage_, n_atoms_stage, 1, 4, sfreq)\n",
    "\n",
    "    print(main_rhythm)"
   ],
   "id": "c7680342c20ea1fe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
